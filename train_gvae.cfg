# Trains a proper Gaussian Neural Variational Document Model (G-NVDM)

# General training meta-parameters
seed = 69
trainModel = true # if set to true, will fit model to "dataFname" tracking progress on "validFname"
dataFname = ng_data/train.vec
validFname = ng_data/valid.vec
graphFname = ng_gnvdm/gnvdm
archType = gaussian-vae
dictFname = ng_data/20ng-lex.dict
miniBatchSize = 20

# general OGraph meta-parameters
n_hid_1 = 50 # num encoder hidden neurons in 1st layer
n_hid_2 = 50 # num encoder hidden neurons in 2nd layer
hidActivation = softsign
outputActivation = softmax
initType = gaussian(0,0.1)
outInitType = gaussian(0,0.1)

# variational autoencoder specific meta-parameters -- alphas control interpolation btwn prior & posterior models
n_lat = 50 # num latent variables
vae_alpha_mu = 0.5 # init at 0.5 -> these will be learned by the model
vae_alpha_sigma = 0.5 # init at 0.5 -> these will be learned by the model
vae_gamma = 0.1 # weights KL term
gamma_iter_bound = 100000 # how many computations/iterations to anneal vae_gamma over (until 1 is reached)

# Optimization meta-parameters
loss_function = neg_log_loss # don't mess w/ this actually, as VAE uses the negative of this to get lower bound expectation
numEpochs = 15
errorMark = 150000
optimizer = sgd
lr = 0.1
norm_rescale = 1

# step-size scheduling meta-parameters
patience = 5 # how many failures tolerated before dividing lr by lr_div
lr_div = 2.0 # factor to divide lr by
epoch_bound = 1 # min num epochs before schedule applied
